cm <- table(Observed = test_set$diabetes, Predicted = pred)
print(cm)
conf_matrix <- confusionMatrix(data = pred, reference = test_set[, ncol(test_set)])
accuracy <- conf_matrix$overall['Accuracy']
f1_score <- conf_matrix$byClass['F1']
# Precyzja, czułość, specyficzność
precision <- diag(cm) / rowSums(cm)
sensitivity <- cm[2,2] / sum(cm[2,])
specificity <- cm[1,1] / sum(cm[1,])
cat("\nk =", k, "\n")
cat("Precyzja =", precision, "\n")
cat("Czułość =", sensitivity, "\n")
cat("Specyficzność =", specificity, "\n\n")
cat("Celność =", accuracy, "\n\n")
cat("F1 =", f1_score, "\n\n")
}
library(mlbench)
# Wczytanie danych Pima Indians Diabetes
data(PimaIndiansDiabetes)
pima <- PimaIndiansDiabetes
# Analiza danych
summary(pima)
str(pima)
any(is.na(pima)) # Czy są jakieś brakujące dane?
pima_clean <- pima
zero_columns <- c("glucose", "pressure", "triceps", "insulin", "mass") # Kolumny, gdzie 0 uznajemy za brakujące wartości
for (column in zero_columns) {
pima_clean[, column][pima_clean[, column] == 0] <- median(pima_clean[, column][pima_clean[, column] != 0], na.rm = TRUE)
}
# Normalizacja danych
pima_scaled <- as.data.frame(scale(pima_clean[, -ncol(pima_clean)])) # Nie skalujemy ostatniej kolumny, która jest etykietą
# Dodanie etykiety z powrotem do zbioru danych
pima_scaled$diabetes <- pima$diabetes
# Podział na zbiory uczące i testowe
set.seed(123) # Dla powtarzalności wyników
index <- sample(1:nrow(pima_scaled), 0.7 * nrow(pima_scaled))
train_set <- pima_scaled[index, ]
test_set <- pima_scaled[-index, ]
library(class)
# Wypróbowanie różnych wartości k
ks <- c(1, 3, 5, 7, 9, 11, 13, 15)
for (k in ks) {
set.seed(123) # Dla powtarzalności wyników
pred <- knn(train = train_set[, -ncol(train_set)], test = test_set[, -ncol(test_set)], cl = train_set$diabetes, k = k)
# Macierz pomyłek
cm <- table(Observed = test_set$diabetes, Predicted = pred)
print(cm)
conf_matrix <- confusionMatrix(data = pred, reference = test_set[, ncol(test_set)])
accuracy <- conf_matrix$overall['Accuracy']
f1_score <- conf_matrix$byClass['F1']
# Precyzja, czułość, specyficzność
precision <- diag(cm) / rowSums(cm)
sensitivity <- cm[2,2] / sum(cm[2,])
specificity <- cm[1,1] / sum(cm[1,])
cat("\nk =", k, "\n")
cat("Precyzja =", precision, "\n")
cat("Czułość =", sensitivity, "\n")
cat("Specyficzność =", specificity, "\n")
cat("Celność =", accuracy, "\n")
cat("F1 =", f1_score, "\n")
}
View(conf_matrix)
View(conf_matrix)
setwd("/home/student/Repositories/data-mining/cwiczenia6/")
real_estate <- read.csv("Real_estate.csv")
real_estate$y = real_estate$Y.house.price.of.unit.area
real_estate$x1 = real_estate$X1.transaction.date
real_estate$x2 = real_estate$X2.house.age
real_estate$x3 = real_estate$X3.distance.to.the.nearest.MRT.station
real_estate$x4 = real_estate$X4.number.of.convenience.stores
real_estate$x5 = real_estate$X5.latitude
real_estate$x6 = real_estate$X6.longitude
library(corrplot)
corr_matrix<-round(cor(real_estate[2:8]),2)
corrplot(corr_matrix)
# Załóżmy, że dane zostały wczytane i są dostępne jako `real_estate`
# Podział danych na zbiór treningowy i testowy
set.seed(123) # Zapewnienie powtarzalności wyników
n <- nrow(real_estate)
splits <- sample(1:n, 0.95 * n)
train_data <- real_estate[splits, ]
test_data <- real_estate[-splits, ]
# Budowa modelu regresji prostej liniowej
linear_model <- lm(y ~ x3, data=train_data)
# Predykcja na 5% danych testowych
predictions_linear <- predict(linear_model, newdata=test_data)
# Ocena jakości modelu
summary(linear_model) # Wyświetla R-squared i inne statystyki
# Budowa modelu regresji wielorakiej
multiple_model <- lm(y ~ x3 + x4 + x5, data=train_data)
# Predykcja na 5% danych testowych
predictions_multiple <- predict(multiple_model, newdata=test_data)
# Ocena jakości modelu
summary(multiple_model)
# Estymacja wartości początkowych
optim_fun <- function(params) {
a <- params[1]
b <- params[2]
c <- params[3]
sum((train_data$y - (a + b * exp(-c * train_data$x3)))^2)
}
# Dobrze jest podać realistyczne wartości początkowe
opt <- optim(c(1, 1, 0.1), optim_fun, method = "BFGS")
# Sprawdzenie wyników
a <- opt$par[1]
b <- opt$par[2]
c <- opt$par[3]
start_vals = list(a=a, b=b, c=c)
# Budowa modelu nieliniowego
nonlinear_model <- nls(y ~ a + b * exp(-c * x3), data = train_data, start = start_vals)
# Predykcja na 5% danych testowych
predictions_nonlinear <- predict(nonlinear_model, newdata=test_data)
# Ocena jakości modelu
summary(nonlinear_model)
library(class)
# Przygotowanie danych (standaryzacja)
scale_train_data <- scale(train_data[,-which(names(train_data) == "y")])
scale_test_data <- scale(test_data[,-which(names(test_data) == "y")])
# Budowa modelu kNN regresji
knn_model <- knnreg(scale_train_data, train_data$y, k=5)
# Predykcje
predictions_knn <- predict(knn_model, data.frame(scale_test_data))
# Ocena jakości modelu
mse_knn <- mean((test_data$y - predictions_knn)^2)
# Obliczamy błędy predykcji dla każdego modelu
mse_linear <- mean((test_data$y - predictions_linear)^2)
mse_multiple <- mean((test_data$y - predictions_multiple)^2)
mse_nonlinear <- mean((test_data$y - predictions_nonlinear)^2)
knn_R2 = (cor(test_data$y, predictions_knn))^2
linear_R2 = (cor(test_data$y, predictions_linear))^2
multiple_R2 = (cor(test_data$y, predictions_multiple))^2
nonlinear_R2 = (cor(test_data$y, predictions_nonlinear))^2
# Porównujemy MSE
mse_comparison <- data.frame(Linear=mse_linear, Multiple=mse_multiple, Nonlinear=mse_nonlinear, kNN=mse_knn)
# Porównujemy R2
R2_comparison <- data.frame(Linear=linear_R2, Multiple=multiple_R2, Nonlinear=nonlinear_R2, kNN=knn_R2)
mse_comparison
R2_comparison
table(iris$Species)
cor(iris[-5])
library(psych)
pairs.panels(iris[-5])
boxplot(Sepal.Length~Species, iris)
#własna funkcja do wykonania standaryzacji lub inaczej normalizacji z-score
stand <-function(x) { (x -mean(x))/(sd(x)) }
iris_std<- as.data.frame(lapply(iris[,c(1,2,3,4)],stand ))
iris_std_sp<-data.frame(iris_std, iris$Species)
#podzbiory
set.seed(123)
sets <- sample(1:nrow(iris), 0.75 * nrow(iris))
train_ir<-iris_std_sp[sets,]
test_ir<-iris_std_sp[-sets,]
#klasy poszczególnych obserwacji w podzbiorach
train_ir_class<-iris[sets,5]
test_ir_class<-iris[-sets,5]
#pakiet do modeli klasyfikacyjnych kNN
library(class)
#model 1a
model_ir3 <- knn(train = train_ir[, 1:4], test = test_ir[,1:4], cl = train_ir_class, k=12)
t_ir3<-table(Species=test_ir_class, Prediction=model_ir3)
acc_ir3<-mean(test_ir_class == model_ir3)
acc_ir3
set.seed(123)
library(MASS)
library(caret)
#funkcja standaryzująca, zamiast niej może być np. scale()
stand <-function(x) { (x -mean(x))/(sd(x)) }
data("Boston")
sets <- sample(1:nrow(Boston), 0.75 * nrow(Boston))
train<-Boston[sets,]
train_std<- as.data.frame(lapply(train[,c(1:13)],stand ))
train_y<-train[,14]
test<-Boston[-sets,]
test_std<- as.data.frame(lapply(test[,c(1:13)],stand ))
test_y<-test[,14]
knnm1<- knnreg(train_std, train_y, k=5)
str(knnm1)
pred_y = predict(knnm1, data.frame(test_std))
mse = mean((test_y - pred_y)^2)
rmse = caret::RMSE(test_y, pred_y)
R2 = (cor(test_y, pred_y))^2
R2
table(iris$Species)
cor(iris[-5])
library(psych)
pairs.panels(iris[-5])
boxplot(Sepal.Length~Species, iris)
#własna funkcja do wykonania standaryzacji lub inaczej normalizacji z-score
stand <-function(x) { (x -mean(x))/(sd(x)) }
iris_std<- as.data.frame(lapply(iris[,c(1,2,3,4)],stand ))
iris_std_sp<-data.frame(iris_std, iris$Species)
#podzbiory
set.seed(123)
sets <- sample(1:nrow(iris), 0.75 * nrow(iris))
train_ir<-iris_std_sp[sets,]
test_ir<-iris_std_sp[-sets,]
#klasy poszczególnych obserwacji w podzbiorach
train_ir_class<-iris[sets,5]
test_ir_class<-iris[-sets,5]
#pakiet do modeli klasyfikacyjnych kNN
library(class)
#model 1a
model_ir3 <- knn(train = train_ir[, 1:4], test = test_ir[,1:4], cl = train_ir_class, k=12)
t_ir3<-table(Species=test_ir_class, Prediction=model_ir3)
acc_ir3<-mean(test_ir_class == model_ir3)
acc_ir3
set.seed(123)
library(MASS)
library(caret)
#funkcja standaryzująca, zamiast niej może być np. scale()
stand <-function(x) { (x -mean(x))/(sd(x)) }
data("Boston")
sets <- sample(1:nrow(Boston), 0.75 * nrow(Boston))
train<-Boston[sets,]
train_std<- as.data.frame(lapply(train[,c(1:13)],stand ))
train_y<-train[,14]
test<-Boston[-sets,]
test_std<- as.data.frame(lapply(test[,c(1:13)],stand ))
test_y<-test[,14]
knnm1<- knnreg(train_std, train_y, k=12)
str(knnm1)
pred_y = predict(knnm1, data.frame(test_std))
mse = mean((test_y - pred_y)^2)
rmse = caret::RMSE(test_y, pred_y)
R2 = (cor(test_y, pred_y))^2
R2
table(iris$Species)
cor(iris[-5])
library(psych)
pairs.panels(iris[-5])
boxplot(Sepal.Length~Species, iris)
#własna funkcja do wykonania standaryzacji lub inaczej normalizacji z-score
stand <-function(x) { (x -mean(x))/(sd(x)) }
iris_std<- as.data.frame(lapply(iris[,c(1,2,3,4)],stand ))
iris_std_sp<-data.frame(iris_std, iris$Species)
#podzbiory
set.seed(123)
sets <- sample(1:nrow(iris), 0.75 * nrow(iris))
train_ir<-iris_std_sp[sets,]
test_ir<-iris_std_sp[-sets,]
#klasy poszczególnych obserwacji w podzbiorach
train_ir_class<-iris[sets,5]
test_ir_class<-iris[-sets,5]
#pakiet do modeli klasyfikacyjnych kNN
library(class)
#model 1a
model_ir3 <- knn(train = train_ir[, 1:4], test = test_ir[,1:4], cl = train_ir_class, k=12)
t_ir3<-table(Species=test_ir_class, Prediction=model_ir3)
acc_ir3<-mean(test_ir_class == model_ir3)
acc_ir3
set.seed(123)
library(MASS)
library(caret)
#funkcja standaryzująca, zamiast niej może być np. scale()
stand <-function(x) { (x -mean(x))/(sd(x)) }
data("Boston")
sets <- sample(1:nrow(Boston), 0.75 * nrow(Boston))
train<-Boston[sets,]
train_std<- as.data.frame(lapply(train[,c(1:13)],stand ))
train_y<-train[,14]
test<-Boston[-sets,]
test_std<- as.data.frame(lapply(test[,c(1:13)],stand ))
test_y<-test[,14]
knnm1<- knnreg(train_std, train_y, k=5)
str(knnm1)
pred_y = predict(knnm1, data.frame(test_std))
mse = mean((test_y - pred_y)^2)
rmse = caret::RMSE(test_y, pred_y)
R2 = (cor(test_y, pred_y))^2
R2
table(iris$Species)
cor(iris[-5])
library(psych)
pairs.panels(iris[-5])
boxplot(Sepal.Length~Species, iris)
#własna funkcja do wykonania standaryzacji lub inaczej normalizacji z-score
stand <-function(x) { (x -mean(x))/(sd(x)) }
iris_std<- as.data.frame(lapply(iris[,c(1,2,3,4)],stand ))
iris_std_sp<-data.frame(iris_std, iris$Species)
#podzbiory
set.seed(123)
sets <- sample(1:nrow(iris), 0.75 * nrow(iris))
train_ir<-iris_std_sp[sets,]
test_ir<-iris_std_sp[-sets,]
#klasy poszczególnych obserwacji w podzbiorach
train_ir_class<-iris[sets,5]
test_ir_class<-iris[-sets,5]
#pakiet do modeli klasyfikacyjnych kNN
library(class)
#model 1a
model_ir3 <- knn(train = train_ir[, 1:4], test = test_ir[,1:4], cl = train_ir_class, k=12)
t_ir3<-table(Species=test_ir_class, Prediction=model_ir3)
acc_ir3<-mean(test_ir_class == model_ir3)
acc_ir3
library(mlbench)
# Wczytanie danych Pima Indians Diabetes
data(PimaIndiansDiabetes)
pima <- PimaIndiansDiabetes
# Analiza danych
summary(pima)
str(pima)
any(is.na(pima)) # Czy są jakieś brakujące dane?
View(pima)
table(iris$Species)
cor(iris[-5])
library(psych)
pairs.panels(iris[-5])
boxplot(Sepal.Length~Species, iris)
#własna funkcja do wykonania standaryzacji lub inaczej normalizacji z-score
stand <-function(x) { (x -mean(x))/(sd(x)) }
iris_std<- as.data.frame(lapply(iris[,c(1,2,3,4)],stand ))
iris_std_sp<-data.frame(iris_std, iris$Species)
#podzbiory
set.seed(123)
sets <- sample(1:nrow(iris), 0.75 * nrow(iris))
train_ir<-iris_std_sp[sets,]
test_ir<-iris_std_sp[-sets,]
#klasy poszczególnych obserwacji w podzbiorach
train_ir_class<-iris[sets,5]
test_ir_class<-iris[-sets,5]
#pakiet do modeli klasyfikacyjnych kNN
library(class)
#model 1a
model_ir3 <- knn(train = train_ir[, 1:4], test = test_ir[,1:4], cl = train_ir_class, k=12)
t_ir3<-table(Species=test_ir_class, Prediction=model_ir3)
acc_ir3<-mean(test_ir_class == model_ir3)
acc_ir3
set.seed(123)
library(MASS)
library(caret)
#funkcja standaryzująca, zamiast niej może być np. scale()
stand <-function(x) { (x -mean(x))/(sd(x)) }
data("Boston")
sets <- sample(1:nrow(Boston), 0.75 * nrow(Boston))
train<-Boston[sets,]
train_std<- as.data.frame(lapply(train[,c(1:13)],stand ))
train_y<-train[,14]
test<-Boston[-sets,]
test_std<- as.data.frame(lapply(test[,c(1:13)],stand ))
test_y<-test[,14]
knnm1<- knnreg(train_std, train_y, k=12)
str(knnm1)
pred_y = predict(knnm1, data.frame(test_std))
mse = mean((test_y - pred_y)^2)
rmse = caret::RMSE(test_y, pred_y)
R2 = (cor(test_y, pred_y))^2
R2
table(iris$Species)
cor(iris[-5])
library(psych)
pairs.panels(iris[-5])
boxplot(Sepal.Length~Species, iris)
#własna funkcja do wykonania standaryzacji lub inaczej normalizacji z-score
stand <-function(x) { (x -mean(x))/(sd(x)) }
iris_std<- as.data.frame(lapply(iris[,c(1,2,3,4)],stand ))
iris_std_sp<-data.frame(iris_std, iris$Species)
#podzbiory
set.seed(123)
sets <- sample(1:nrow(iris), 0.75 * nrow(iris))
train_ir<-iris_std_sp[sets,]
test_ir<-iris_std_sp[-sets,]
#klasy poszczególnych obserwacji w podzbiorach
train_ir_class<-iris[sets,5]
test_ir_class<-iris[-sets,5]
#pakiet do modeli klasyfikacyjnych kNN
library(class)
#model 1a
model_ir3 <- knn(train = train_ir[, 1:4], test = test_ir[,1:4], cl = train_ir_class, k=12)
t_ir3<-table(Species=test_ir_class, Prediction=model_ir3)
acc_ir3<-mean(test_ir_class == model_ir3)
acc_ir3
set.seed(123)
library(MASS)
library(caret)
#funkcja standaryzująca, zamiast niej może być np. scale()
stand <-function(x) { (x -mean(x))/(sd(x)) }
data("Boston")
sets <- sample(1:nrow(Boston), 0.75 * nrow(Boston))
train<-Boston[sets,]
train_std<- as.data.frame(lapply(train[,c(1:13)],stand ))
train_y<-train[,14]
test<-Boston[-sets,]
test_std<- as.data.frame(lapply(test[,c(1:13)],stand ))
test_y<-test[,14]
knnm1<- knnreg(train_std, train_y, k=12)
str(knnm1)
pred_y = predict(knnm1, data.frame(test_std))
mse = mean((test_y - pred_y)^2)
rmse = caret::RMSE(test_y, pred_y)
R2 = (cor(test_y, pred_y))^2
acc_ir3
R2
setwd("/home/student/Repositories/data-mining/cwiczenia6/")
real_estate <- read.csv("Real_estate.csv")
real_estate$y = real_estate$Y.house.price.of.unit.area
real_estate$x1 = real_estate$X1.transaction.date
real_estate$x2 = real_estate$X2.house.age
real_estate$x3 = real_estate$X3.distance.to.the.nearest.MRT.station
real_estate$x4 = real_estate$X4.number.of.convenience.stores
real_estate$x5 = real_estate$X5.latitude
real_estate$x6 = real_estate$X6.longitude
library(corrplot)
corr_matrix<-round(cor(real_estate[2:8]),2)
corrplot(corr_matrix)
# Załóżmy, że dane zostały wczytane i są dostępne jako `real_estate`
# Podział danych na zbiór treningowy i testowy
set.seed(123) # Zapewnienie powtarzalności wyników
n <- nrow(real_estate)
splits <- sample(1:n, 0.95 * n)
train_data <- real_estate[splits, ]
test_data <- real_estate[-splits, ]
# Budowa modelu regresji prostej liniowej
linear_model <- lm(y ~ x3, data=train_data)
# Predykcja na 5% danych testowych
predictions_linear <- predict(linear_model, newdata=test_data)
# Ocena jakości modelu
summary(linear_model) # Wyświetla R-squared i inne statystyki
# Budowa modelu regresji wielorakiej
multiple_model <- lm(y ~ x3 + x4 + x5, data=train_data)
# Predykcja na 5% danych testowych
predictions_multiple <- predict(multiple_model, newdata=test_data)
# Ocena jakości modelu
summary(multiple_model)
# Estymacja wartości początkowych
optim_fun <- function(params) {
a <- params[1]
b <- params[2]
c <- params[3]
sum((train_data$y - (a + b * exp(-c * train_data$x3)))^2)
}
# Dobrze jest podać realistyczne wartości początkowe
opt <- optim(c(1, 1, 0.1), optim_fun, method = "BFGS")
# Sprawdzenie wyników
a <- opt$par[1]
b <- opt$par[2]
c <- opt$par[3]
start_vals = list(a=a, b=b, c=c)
# Budowa modelu nieliniowego
nonlinear_model <- nls(y ~ a + b * exp(-c * x3), data = train_data, start = start_vals)
# Predykcja na 5% danych testowych
predictions_nonlinear <- predict(nonlinear_model, newdata=test_data)
# Ocena jakości modelu
summary(nonlinear_model)
library(class)
# Przygotowanie danych (standaryzacja)
scale_train_data <- scale(train_data[,-which(names(train_data) == "y")])
scale_test_data <- scale(test_data[,-which(names(test_data) == "y")])
# Budowa modelu kNN regresji
knn_model <- knnreg(scale_train_data, train_data$y, k=5)
# Predykcje
predictions_knn <- predict(knn_model, data.frame(scale_test_data))
# Ocena jakości modelu
mse_knn <- mean((test_data$y - predictions_knn)^2)
# Obliczamy błędy predykcji dla każdego modelu
mse_linear <- mean((test_data$y - predictions_linear)^2)
mse_multiple <- mean((test_data$y - predictions_multiple)^2)
mse_nonlinear <- mean((test_data$y - predictions_nonlinear)^2)
knn_R2 = (cor(test_data$y, predictions_knn))^2
linear_R2 = (cor(test_data$y, predictions_linear))^2
multiple_R2 = (cor(test_data$y, predictions_multiple))^2
nonlinear_R2 = (cor(test_data$y, predictions_nonlinear))^2
# Porównujemy MSE
mse_comparison <- data.frame(Linear=mse_linear, Multiple=mse_multiple, Nonlinear=mse_nonlinear, kNN=mse_knn)
# Porównujemy R2
R2_comparison <- data.frame(Linear=linear_R2, Multiple=multiple_R2, Nonlinear=nonlinear_R2, kNN=knn_R2)
mse_comparison
R2_comparison
library(mlbench)
# Wczytanie danych Pima Indians Diabetes
data(PimaIndiansDiabetes)
pima <- PimaIndiansDiabetes
# Analiza danych
summary(pima)
str(pima)
any(is.na(pima)) # Czy są jakieś brakujące dane?
pima_clean <- pima
zero_columns <- c("glucose", "pressure", "triceps", "insulin", "mass") # Kolumny, gdzie 0 uznajemy za brakujące wartości
for (column in zero_columns) {
pima_clean[, column][pima_clean[, column] == 0] <- median(pima_clean[, column][pima_clean[, column] != 0], na.rm = TRUE)
}
# Normalizacja danych
pima_scaled <- as.data.frame(scale(pima_clean[, -ncol(pima_clean)])) # Nie skalujemy ostatniej kolumny, która jest etykietą
# Dodanie etykiety z powrotem do zbioru danych
pima_scaled$diabetes <- pima$diabetes
# Podział na zbiory uczące i testowe
set.seed(123) # Dla powtarzalności wyników
index <- sample(1:nrow(pima_scaled), 0.7 * nrow(pima_scaled))
train_set <- pima_scaled[index, ]
test_set <- pima_scaled[-index, ]
library(class)
# Wypróbowanie różnych wartości k
ks <- c(1, 3, 5, 7, 9, 11, 13, 15)
for (k in ks) {
set.seed(123) # Dla powtarzalności wyników
pred <- knn(train = train_set[, -ncol(train_set)], test = test_set[, -ncol(test_set)], cl = train_set$diabetes, k = k)
# Macierz pomyłek
cm <- table(Observed = test_set$diabetes, Predicted = pred)
print(cm)
conf_matrix <- confusionMatrix(data = pred, reference = test_set[, ncol(test_set)])
accuracy <- conf_matrix$overall['Accuracy']
f1_score <- conf_matrix$byClass['F1']
# Precyzja, czułość, specyficzność
precision <- diag(cm) / rowSums(cm)
sensitivity <- cm[2,2] / sum(cm[2,])
specificity <- cm[1,1] / sum(cm[1,])
cat("\nk =", k, "\n")
cat("Precyzja =", precision, "\n")
cat("Czułość =", sensitivity, "\n")
cat("Specyficzność =", specificity, "\n")
cat("Celność =", accuracy, "\n")
cat("F1 =", f1_score, "\n")
}
